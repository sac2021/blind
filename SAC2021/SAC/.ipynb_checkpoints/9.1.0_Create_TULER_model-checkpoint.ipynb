{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import gc\n",
    "import os\n",
    "import itertools\n",
    "from os import path\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from glob import glob\n",
    "from joblib import load, dump\n",
    "from keras.preprocessing import sequence\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.layers import Dense, LSTM, GRU, Bidirectional, Concatenate, Add, Average, SimpleRNN, Embedding, Dropout, Input, Masking\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from pymove import metrics\n",
    "from pymove import geohash, classification as clf\n",
    "from pymove import TulerClassifier as tul\n",
    "from pymove import DeepeSTClassifier as DST\n",
    "from pymove import notity as nt\n",
    "from pymove import utils\n",
    "from pymove import lossutils\n",
    "#from pandas_profiling import ProfileReport\n",
    "from datetime import datetime\n",
    "#os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "#os.environ['KERAS_BACKEND'] = 'theano'\n",
    "from keras.optimizers import RMSprop, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'brightkite' #['fousquare_nyc', 'brightkite', 'foursquare_global', gowalla,'criminal_id', 'criminal_activity']\n",
    "file_train = 'data/{}/_train.csv.gz'.format(dataset)\n",
    "file_val = 'data/{}/_val.csv.gz'.format(dataset)\n",
    "file_test = 'data/{}/_test.csv.gz'.format(dataset)\n",
    "df_train = pd.read_csv(file_train)\n",
    "df_val = pd.read_csv(file_val)\n",
    "df_test = pd.read_csv(file_test)\n",
    "df = pd.concat([df_train, df_val, df_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tid_train = df_train['tid'].unique()     \n",
    "tid_val = df_val['tid'].unique()     \n",
    "tid_test = df_test['tid'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_poi = 'poi'\n",
    "features = ['poi', 'label', 'tid']\n",
    "data = [df_train[features], df_val[features], df_test[features]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###########      DATA PREPARATION        ###########\n",
      "\n",
      "... input total: {input_total}\n",
      "... concat dataframe\n",
      "... tid_0: 4652\n",
      "... tid_1: 997\n",
      "... tid_2: 997\n",
      "... col_name: ['poi', 'label', 'tid']...\n",
      "... num_classes: 197\n",
      "... max_lenght: 150\n",
      "... removing column tid of attr\n",
      "... removing column label of attr\n",
      "\n",
      "\n",
      "#####   Encoding string data to integer   ######\n",
      "... encoding: poi\n",
      "\n",
      "\n",
      "###########      Generating y_train and y_test     ###########\n",
      "... Label encoding on label y\n",
      "... input total: 3\n",
      "\n",
      "\n",
      "###########      Generating X_Train and X_Test     ###########\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nicksson/miniconda3/envs/tnz/lib/python3.7/site-packages/sklearn/preprocessing/_label.py:251: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "X, y = DST.generate_X_y_nn(data=data,\n",
    "                y_one_hot_encodding=False,\n",
    "                label_y='label',\n",
    "                label_segment='tid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[0]\n",
    "X_val = X[1]\n",
    "X_test = X[2]\n",
    "y_train = y[0]\n",
    "y_val = y[1]\n",
    "y_test = y[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRID SEARCH TO TULER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 197\n",
    "max_lenght = 150\n",
    "vocab_size = X[0][0].max() + 1\n",
    "rnn=['bilstm']\n",
    "units = [200, 300]\n",
    "stack = [1,2,3]\n",
    "dropout =[0.5]\n",
    "embedding_size = [100, 200, 300]\n",
    "batch_size = [64]\n",
    "epochs = [1000]\n",
    "patience = [20]\n",
    "monitor = ['val_acc']\n",
    "optimizer = ['ada']\n",
    "learning_rate = [0.001]\n",
    "features = [['tid','label','poi']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 18 iteration\n"
     ]
    }
   ],
   "source": [
    "total = len(rnn)*len(units)*len(stack)* len(dropout)* len(embedding_size)* \\\n",
    "        len(batch_size)*len(epochs) * len(patience) *len(monitor) * len(learning_rate) *\\\n",
    "        len(features) \n",
    "print('There are {} iteration'.format(total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_file = 'ICTAI/exp2/{}/tuler/'.format(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nicksson/miniconda3/envs/tnz/lib/python3.7/site-packages/ipykernel_launcher.py:3: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1da795936d1e454c836306e9960fda88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=18.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating model...\n",
      "ICTAI/exp2/brightkite/tuler/bi_tuler-b-200-0.5-100-64-1000-20-val_acc-0.001-1.csv\n",
      "... max_lenght: 150\n",
      "... vocab_size: 4085\n",
      "... classes: 197\n",
      "... Creating stack to TULER\n",
      "\n",
      "\n",
      "########      Compiling TULER Model    #########\n",
      "... Defining checkpoint\n",
      "... Starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nicksson/miniconda3/envs/tnz/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4652 samples, validate on 997 samples\n",
      "Epoch 1/1000\n",
      "4652/4652 [==============================] - 11s 2ms/step - loss: 5.0905 - acc: 0.0527 - val_loss: 4.7290 - val_acc: 0.1454\n",
      "Epoch 2/1000\n",
      "4652/4652 [==============================] - 10s 2ms/step - loss: 3.8703 - acc: 0.2408 - val_loss: 3.1558 - val_acc: 0.3470\n",
      "Epoch 3/1000\n",
      "4652/4652 [==============================] - 11s 2ms/step - loss: 2.8892 - acc: 0.3891 - val_loss: 2.5017 - val_acc: 0.5135\n",
      "Epoch 4/1000\n",
      "4652/4652 [==============================] - 10s 2ms/step - loss: 2.2476 - acc: 0.5123 - val_loss: 1.9180 - val_acc: 0.6239\n",
      "Epoch 5/1000\n",
      "4652/4652 [==============================] - 10s 2ms/step - loss: 2.0901 - acc: 0.5398 - val_loss: 1.7254 - val_acc: 0.6730\n",
      "Epoch 6/1000\n",
      "4652/4652 [==============================] - 10s 2ms/step - loss: 1.3645 - acc: 0.7113 - val_loss: 1.8214 - val_acc: 0.5878\n",
      "Epoch 7/1000\n",
      "4652/4652 [==============================] - 10s 2ms/step - loss: 1.2768 - acc: 0.7270 - val_loss: 1.0083 - val_acc: 0.8305\n",
      "Epoch 8/1000\n",
      "4652/4652 [==============================] - 10s 2ms/step - loss: 0.8147 - acc: 0.8463 - val_loss: 0.8681 - val_acc: 0.8375\n",
      "Epoch 9/1000\n",
      "4652/4652 [==============================] - 10s 2ms/step - loss: 0.7190 - acc: 0.8594 - val_loss: 0.7746 - val_acc: 0.8596\n",
      "Epoch 10/1000\n",
      "4652/4652 [==============================] - 11s 2ms/step - loss: 0.8089 - acc: 0.8242 - val_loss: 0.7033 - val_acc: 0.8726\n",
      "Epoch 11/1000\n",
      "4652/4652 [==============================] - 11s 2ms/step - loss: 0.5153 - acc: 0.8927 - val_loss: 0.5960 - val_acc: 0.8877\n",
      "Epoch 12/1000\n",
      "4652/4652 [==============================] - 11s 2ms/step - loss: 0.4468 - acc: 0.9084 - val_loss: 0.5847 - val_acc: 0.8987\n",
      "Epoch 13/1000\n",
      "4652/4652 [==============================] - 11s 2ms/step - loss: 0.5333 - acc: 0.8895 - val_loss: 0.5778 - val_acc: 0.8877\n",
      "Epoch 14/1000\n",
      "4652/4652 [==============================] - 11s 2ms/step - loss: 0.4664 - acc: 0.9015 - val_loss: 0.5180 - val_acc: 0.9017\n",
      "Epoch 15/1000\n",
      "4652/4652 [==============================] - 10s 2ms/step - loss: 0.3597 - acc: 0.9288 - val_loss: 0.5122 - val_acc: 0.8977\n",
      "Epoch 16/1000\n",
      "4652/4652 [==============================] - 10s 2ms/step - loss: 0.5553 - acc: 0.8745 - val_loss: 0.5272 - val_acc: 0.9027\n",
      "Epoch 17/1000\n",
      "4652/4652 [==============================] - 10s 2ms/step - loss: 0.8418 - acc: 0.8003 - val_loss: 0.8471 - val_acc: 0.8415\n",
      "Epoch 18/1000\n",
      "4652/4652 [==============================] - 10s 2ms/step - loss: 0.9489 - acc: 0.7732 - val_loss: 0.8801 - val_acc: 0.8205\n",
      "Epoch 19/1000\n",
      "4652/4652 [==============================] - 10s 2ms/step - loss: 0.6711 - acc: 0.8403 - val_loss: 0.5448 - val_acc: 0.8957\n",
      "Epoch 20/1000\n",
      "4652/4652 [==============================] - 10s 2ms/step - loss: 0.4040 - acc: 0.9151 - val_loss: 0.4792 - val_acc: 0.9087\n",
      "Epoch 21/1000\n",
      "4652/4652 [==============================] - 11s 2ms/step - loss: 0.4253 - acc: 0.9050 - val_loss: 0.5515 - val_acc: 0.8987\n",
      "Epoch 22/1000\n",
      "4652/4652 [==============================] - 11s 2ms/step - loss: 0.3735 - acc: 0.9164 - val_loss: 0.6184 - val_acc: 0.8636\n",
      "Epoch 23/1000\n",
      "4652/4652 [==============================] - 11s 2ms/step - loss: 0.4885 - acc: 0.8831 - val_loss: 0.4984 - val_acc: 0.8997\n",
      "Epoch 24/1000\n",
      "4652/4652 [==============================] - 10s 2ms/step - loss: 0.3330 - acc: 0.9267 - val_loss: 0.4812 - val_acc: 0.8977\n",
      "Epoch 25/1000\n",
      "4652/4652 [==============================] - 11s 2ms/step - loss: 0.2740 - acc: 0.9383 - val_loss: 0.4161 - val_acc: 0.9168\n",
      "Epoch 26/1000\n",
      "4652/4652 [==============================] - 11s 2ms/step - loss: 0.2224 - acc: 0.9484 - val_loss: 0.4093 - val_acc: 0.9258\n",
      "Epoch 27/1000\n",
      "4652/4652 [==============================] - 11s 2ms/step - loss: 0.2060 - acc: 0.9525 - val_loss: 0.4385 - val_acc: 0.9157\n",
      "Epoch 28/1000\n",
      "4652/4652 [==============================] - 10s 2ms/step - loss: 0.2186 - acc: 0.9501 - val_loss: 0.4622 - val_acc: 0.9178\n",
      "Epoch 29/1000\n",
      "4652/4652 [==============================] - 10s 2ms/step - loss: 0.1989 - acc: 0.9534 - val_loss: 0.3956 - val_acc: 0.9228\n",
      "Epoch 30/1000\n",
      "4652/4652 [==============================] - 10s 2ms/step - loss: 0.2126 - acc: 0.9501 - val_loss: 0.4822 - val_acc: 0.9107\n",
      "Epoch 31/1000\n",
      "4652/4652 [==============================] - 10s 2ms/step - loss: 0.2667 - acc: 0.9351 - val_loss: 0.5677 - val_acc: 0.8796\n",
      "Epoch 32/1000\n",
      "4652/4652 [==============================] - 10s 2ms/step - loss: 0.3422 - acc: 0.9172 - val_loss: 0.4496 - val_acc: 0.9117\n",
      "Epoch 33/1000\n",
      "4652/4652 [==============================] - 10s 2ms/step - loss: 0.2639 - acc: 0.9387 - val_loss: 0.4404 - val_acc: 0.9147\n",
      "Epoch 34/1000\n",
      "4652/4652 [==============================] - 10s 2ms/step - loss: 0.2393 - acc: 0.9439 - val_loss: 0.4189 - val_acc: 0.9198\n",
      "Epoch 35/1000\n",
      "4652/4652 [==============================] - 10s 2ms/step - loss: 0.2159 - acc: 0.9460 - val_loss: 0.3968 - val_acc: 0.9218\n",
      "Epoch 36/1000\n",
      "4652/4652 [==============================] - 10s 2ms/step - loss: 0.3815 - acc: 0.9052 - val_loss: 0.5251 - val_acc: 0.8957\n",
      "Epoch 37/1000\n",
      "4652/4652 [==============================] - 10s 2ms/step - loss: 0.2705 - acc: 0.9353 - val_loss: 0.4281 - val_acc: 0.9117\n",
      "Epoch 38/1000\n",
      "4652/4652 [==============================] - 10s 2ms/step - loss: 0.2612 - acc: 0.9329 - val_loss: 0.5028 - val_acc: 0.8937\n",
      "Epoch 39/1000\n",
      "4652/4652 [==============================] - 10s 2ms/step - loss: 0.2381 - acc: 0.9405 - val_loss: 0.4351 - val_acc: 0.9157\n",
      "Epoch 40/1000\n",
      "4652/4652 [==============================] - 11s 2ms/step - loss: 0.2771 - acc: 0.9250 - val_loss: 0.4950 - val_acc: 0.9127\n",
      "Epoch 41/1000\n",
      "4652/4652 [==============================] - 11s 2ms/step - loss: 0.2329 - acc: 0.9420 - val_loss: 0.4473 - val_acc: 0.9168\n",
      "Epoch 42/1000\n",
      "4652/4652 [==============================] - 11s 2ms/step - loss: 0.2092 - acc: 0.9463 - val_loss: 0.4375 - val_acc: 0.9107\n",
      "Epoch 43/1000\n",
      "4652/4652 [==============================] - 10s 2ms/step - loss: 0.1695 - acc: 0.9568 - val_loss: 0.3746 - val_acc: 0.9278\n",
      "Epoch 44/1000\n",
      "4652/4652 [==============================] - 10s 2ms/step - loss: 0.1536 - acc: 0.9587 - val_loss: 0.3928 - val_acc: 0.9228\n",
      "Epoch 45/1000\n",
      "4652/4652 [==============================] - 10s 2ms/step - loss: 0.2522 - acc: 0.9368 - val_loss: 0.5162 - val_acc: 0.8977\n",
      "Epoch 46/1000\n",
      "4652/4652 [==============================] - 10s 2ms/step - loss: 0.2372 - acc: 0.9351 - val_loss: 0.4446 - val_acc: 0.9208\n",
      "Epoch 47/1000\n",
      "4652/4652 [==============================] - 11s 2ms/step - loss: 0.2015 - acc: 0.9495 - val_loss: 0.3815 - val_acc: 0.9278\n",
      "Epoch 48/1000\n",
      "4652/4652 [==============================] - 10s 2ms/step - loss: 0.1713 - acc: 0.9542 - val_loss: 0.4034 - val_acc: 0.9168\n",
      "Epoch 49/1000\n",
      "4652/4652 [==============================] - 10s 2ms/step - loss: 0.1731 - acc: 0.9521 - val_loss: 0.3894 - val_acc: 0.9248\n",
      "Epoch 50/1000\n",
      "4652/4652 [==============================] - 10s 2ms/step - loss: 0.1517 - acc: 0.9598 - val_loss: 0.3893 - val_acc: 0.9288\n",
      "Epoch 51/1000\n",
      "4652/4652 [==============================] - 11s 2ms/step - loss: 0.1402 - acc: 0.9622 - val_loss: 0.3781 - val_acc: 0.9268\n",
      "Epoch 52/1000\n",
      "4652/4652 [==============================] - 11s 2ms/step - loss: 0.1405 - acc: 0.9637 - val_loss: 0.3739 - val_acc: 0.9288\n",
      "Epoch 53/1000\n",
      "4652/4652 [==============================] - 10s 2ms/step - loss: 0.1448 - acc: 0.9572 - val_loss: 0.3978 - val_acc: 0.9248\n",
      "Epoch 54/1000\n",
      "4652/4652 [==============================] - 10s 2ms/step - loss: 0.1582 - acc: 0.9600 - val_loss: 0.3921 - val_acc: 0.9228\n",
      "Epoch 55/1000\n",
      "4652/4652 [==============================] - 10s 2ms/step - loss: 0.1309 - acc: 0.9639 - val_loss: 0.3553 - val_acc: 0.9358\n",
      "Epoch 56/1000\n",
      "4652/4652 [==============================] - 10s 2ms/step - loss: 0.1258 - acc: 0.9628 - val_loss: 0.3436 - val_acc: 0.9348\n",
      "Epoch 57/1000\n",
      "4652/4652 [==============================] - 10s 2ms/step - loss: 0.1104 - acc: 0.9686 - val_loss: 0.3539 - val_acc: 0.9358\n",
      "Epoch 58/1000\n",
      "4652/4652 [==============================] - 10s 2ms/step - loss: 0.1887 - acc: 0.9454 - val_loss: 0.4461 - val_acc: 0.8997\n",
      "Epoch 59/1000\n",
      "4652/4652 [==============================] - 10s 2ms/step - loss: 0.2027 - acc: 0.9460 - val_loss: 0.4536 - val_acc: 0.9117\n",
      "Epoch 60/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4652/4652 [==============================] - 10s 2ms/step - loss: 0.1751 - acc: 0.9518 - val_loss: 0.4397 - val_acc: 0.9268\n",
      "Epoch 61/1000\n",
      "4652/4652 [==============================] - 10s 2ms/step - loss: 0.3176 - acc: 0.9114 - val_loss: 0.4015 - val_acc: 0.9198\n",
      "Epoch 62/1000\n",
      "4652/4652 [==============================] - 11s 2ms/step - loss: 0.2112 - acc: 0.9433 - val_loss: 0.3905 - val_acc: 0.9218\n",
      "Epoch 63/1000\n",
      "4652/4652 [==============================] - 11s 2ms/step - loss: 0.2105 - acc: 0.9417 - val_loss: 0.4468 - val_acc: 0.9047\n",
      "Epoch 64/1000\n",
      "4652/4652 [==============================] - 10s 2ms/step - loss: 0.2075 - acc: 0.9409 - val_loss: 0.3789 - val_acc: 0.9238\n",
      "Epoch 65/1000\n",
      "4652/4652 [==============================] - 10s 2ms/step - loss: 0.1835 - acc: 0.9480 - val_loss: 0.4149 - val_acc: 0.9238\n",
      "Epoch 66/1000\n",
      "4652/4652 [==============================] - 10s 2ms/step - loss: 0.2430 - acc: 0.9349 - val_loss: 0.5312 - val_acc: 0.9027\n",
      "Epoch 67/1000\n",
      "4652/4652 [==============================] - 11s 2ms/step - loss: 0.4124 - acc: 0.8867 - val_loss: 0.4780 - val_acc: 0.9077\n",
      "Epoch 68/1000\n",
      "4652/4652 [==============================] - 11s 2ms/step - loss: 0.3134 - acc: 0.9134 - val_loss: 0.4483 - val_acc: 0.9147\n",
      "Epoch 69/1000\n",
      "4652/4652 [==============================] - 11s 2ms/step - loss: 0.2069 - acc: 0.9433 - val_loss: 0.4111 - val_acc: 0.9238\n",
      "Epoch 70/1000\n",
      "4652/4652 [==============================] - 10s 2ms/step - loss: 0.1661 - acc: 0.9542 - val_loss: 0.4145 - val_acc: 0.9218\n",
      "Epoch 71/1000\n",
      "4652/4652 [==============================] - 10s 2ms/step - loss: 0.1700 - acc: 0.9546 - val_loss: 0.4221 - val_acc: 0.9178\n",
      "Epoch 72/1000\n",
      "4652/4652 [==============================] - 10s 2ms/step - loss: 0.1440 - acc: 0.9598 - val_loss: 0.3971 - val_acc: 0.9238\n",
      "Epoch 73/1000\n",
      "4652/4652 [==============================] - 11s 2ms/step - loss: 0.1327 - acc: 0.9624 - val_loss: 0.4280 - val_acc: 0.9288\n",
      "Epoch 74/1000\n",
      "4652/4652 [==============================] - 11s 2ms/step - loss: 0.1162 - acc: 0.9682 - val_loss: 0.4076 - val_acc: 0.9238\n",
      "Epoch 75/1000\n",
      "4652/4652 [==============================] - 10s 2ms/step - loss: 0.1108 - acc: 0.9682 - val_loss: 0.4062 - val_acc: 0.9258\n",
      "Epoch 76/1000\n",
      "4652/4652 [==============================] - 10s 2ms/step - loss: 0.1054 - acc: 0.9686 - val_loss: 0.4006 - val_acc: 0.9298\n",
      "Epoch 77/1000\n",
      "4652/4652 [==============================] - 10s 2ms/step - loss: 0.1036 - acc: 0.9701 - val_loss: 0.4121 - val_acc: 0.9228\n",
      "Epoch 78/1000\n",
      "4652/4652 [==============================] - 11s 2ms/step - loss: 0.0938 - acc: 0.9697 - val_loss: 0.4044 - val_acc: 0.9238\n",
      "Epoch 79/1000\n",
      "4608/4652 [============================>.] - ETA: 0s - loss: 0.0936 - acc: 0.9709"
     ]
    }
   ],
   "source": [
    "for c in tqdm(itertools.product(rnn, units, stack, dropout, embedding_size,\\\n",
    "                                batch_size,epochs, patience, monitor, learning_rate,\\\n",
    "                                features), total=total):\n",
    "    rnn=c[0]\n",
    "    un=c[1]\n",
    "    st=c[2]\n",
    "    dp=c[3]\n",
    "    es=c[4]\n",
    "    bs=c[5]\n",
    "    epoch=c[6]\n",
    "    pat=c[7]\n",
    "    mon=c[8]\n",
    "    lr=c[9]\n",
    "    fet=[10]\n",
    "\n",
    "    filename = dir_file + 'bi_tuler-{}-{}-{}-{}-{}-{}-{}-{}-{}-{}.csv'.format(rnn, un, dp, es, bs,\\\n",
    "                                                                              epoch, pat, mon, lr, st,\\\n",
    "                                                                              fet)\n",
    "    if not path.exists(dir_file):\n",
    "        print('this directory {} is not exist'.format(dir_file))\n",
    "        break\n",
    "    elif path.exists(filename):\n",
    "        print('skip ---> {}\\n'.format(filename))\n",
    "    else:\n",
    "        print('Creating model...')\n",
    "        print(filename)\n",
    "    \n",
    "        bituler = tul.BiTulerLSTM(max_lenght=max_lenght,    \n",
    "                    num_classes=num_classes,\n",
    "                    vocab_size=vocab_size,\n",
    "                    rnn_units=un,\n",
    "                    dropout=dp,\n",
    "                    embedding_size=es,\n",
    "                    stack=st)\n",
    "\n",
    "        bituler.fit(X_train, y_train,\n",
    "                    X_val, y_val,\n",
    "                    batch_size=bs,\n",
    "                    epochs=epoch,\n",
    "                    learning_rate=lr,\n",
    "                    save_model=False,\n",
    "                    save_best_only=False,\n",
    "                    save_weights_only=False)\n",
    "\n",
    "        validation_report = bituler.predict(X_val, y_val)\n",
    "        validation_report.to_csv(filename, index=False)\n",
    "        bituler.free()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COLECT VALIDATION RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymove import utils\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = utils.get_filenames_subdirectories(dir_file)\n",
    "files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "marksplit = '-'\n",
    "for f in files:\n",
    "    df_ = pd.read_csv(f)\n",
    "    df_['rnn']=   f.split(marksplit)[1]\n",
    "    df_['md']=     f.split(marksplit)[2]\n",
    "    df_['st']=     f.split(marksplit)[3]\n",
    "    df_['dp'] = f.split(marksplit)[4]\n",
    "    df_['es'] = f.split(marksplit)[5]\n",
    "    df_['bs'] = f.split(marksplit)[6]\n",
    "    df_['epoch'] = f.split(marksplit)[7]\n",
    "    df_['pat'] = f.split(marksplit)[8]\n",
    "    df_['loss']  = f.split(marksplit)[9]\n",
    "    df_['mon'] = f.split(marksplit)[10]\n",
    "    df_['lr'] = f.split(marksplit)[11]\n",
    "    df_['fet'] = f.split(marksplit)[12].split('.csv')[0]\n",
    "    data.append(df_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = pd.concat(data)\n",
    "df_result.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.sort_values('acc', ascending=False, inplace=True)\n",
    "df_result.iloc[:50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
